{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91124f4b-2e45-4a46-98de-52c3f6f3f5a9",
   "metadata": {
    "id": "91124f4b-2e45-4a46-98de-52c3f6f3f5a9"
   },
   "source": [
    "## **1.Module Not Found Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3b401c-cedb-469d-b79d-8c3acd4011f8",
   "metadata": {
    "id": "dd3b401c-cedb-469d-b79d-8c3acd4011f8",
    "outputId": "3d15f2fe-9fca-4f96-a078-8b234742af97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 10:55:30.299530: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/harikrishnan/Documents/anaconda3/envs/myenv/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Missing import for TensorFlow\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Generate dummy data\u001b[39;00m\n\u001b[32m      8\u001b[39m X_train = np.random.rand(\u001b[32m100\u001b[39m, \u001b[32m10\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow.keras.layer'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Missing import for TensorFlow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layer import Dense\n",
    "\n",
    "# Generate dummy data\n",
    "X_train = np.random.rand(100, 10)\n",
    "Y_train = np.random.randint(0, 2, size=(100,))\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(10,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89438662-8a79-44be-a241-3b47ee4f2b5f",
   "metadata": {
    "id": "89438662-8a79-44be-a241-3b47ee4f2b5f"
   },
   "source": [
    "## **1.Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3591db08-35d1-4b2e-947b-409572adabe7",
   "metadata": {
    "id": "3591db08-35d1-4b2e-947b-409572adabe7",
    "outputId": "5a8aea54-af44-4ddd-965a-4728dfa18f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harikrishnan/Documents/anaconda3/envs/myenv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5100 - loss: 0.6848  \n",
      "Epoch 2/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5400 - loss: 0.6822 \n",
      "Epoch 3/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5400 - loss: 0.6811 \n",
      "Epoch 4/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5300 - loss: 0.6802 \n",
      "Epoch 5/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5400 - loss: 0.6792 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14503f610>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf  # Added missing import\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Generate dummy data\n",
    "X_train = np.random.rand(100, 10)\n",
    "y_train = np.random.randint(0, 2, size=(100,))\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(10,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e65f8e-6135-4d12-aa11-e1f48a29dc69",
   "metadata": {
    "id": "c4e65f8e-6135-4d12-aa11-e1f48a29dc69"
   },
   "source": [
    "## **2.Mismatched Input Shape in CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019a3404-e926-4bf1-81dd-92f0052c3078",
   "metadata": {
    "id": "019a3404-e926-4bf1-81dd-92f0052c3078",
    "outputId": "d5ad740a-6699-4034-d2af-34bfcaf6f30b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harikrishnan/Documents/anaconda3/envs/myenv/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 32, 32), dtype=float32) with name 'keras_tensor_3' and path ''. Expected shape (None, 32, 32, 3), but input has incompatible shape (None, 32, 32)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 32, 32), dtype=float32)\n  • training=True\n  • mask=None\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     11\u001b[39m model = Sequential([\n\u001b[32m     12\u001b[39m     Conv2D(\u001b[32m32\u001b[39m, (\u001b[32m3\u001b[39m,\u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m, input_shape=(\u001b[32m32\u001b[39m,\u001b[32m32\u001b[39m,\u001b[32m3\u001b[39m)),\n\u001b[32m     13\u001b[39m     Flatten(),\n\u001b[32m     14\u001b[39m     Dense(\u001b[32m10\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     15\u001b[39m ])\n\u001b[32m     17\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=\u001b[33m'\u001b[39m\u001b[33msparse_categorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m, metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m model.fit(X_train, y_train, epochs=\u001b[32m5\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/anaconda3/envs/myenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/anaconda3/envs/myenv/lib/python3.11/site-packages/keras/src/models/functional.py:278\u001b[39m, in \u001b[36mFunctional._adjust_input_rank\u001b[39m\u001b[34m(self, flat_inputs)\u001b[39m\n\u001b[32m    276\u001b[39m     flat_paths_and_inputs = tree.flatten_with_path(\u001b[38;5;28mself\u001b[39m._inputs_struct)\n\u001b[32m    277\u001b[39m     path = \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m flat_paths_and_inputs[i][\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    279\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with name \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    280\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._inputs[i].name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m and path \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Expected shape \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    281\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    282\u001b[39m     )\n\u001b[32m    283\u001b[39m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[31mValueError\u001b[39m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, 32, 32), dtype=float32) with name 'keras_tensor_3' and path ''. Expected shape (None, 32, 32, 3), but input has incompatible shape (None, 32, 32)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 32, 32), dtype=float32)\n  • training=True\n  • mask=None\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "\n",
    "# Generate dummy image data\n",
    "X_train = np.random.rand(100, 32, 32)  # Error: Missing the channel dimension\n",
    "y_train = np.random.randint(0, 10, size=(100,))\n",
    "\n",
    "# Define CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce51ed3-f5c7-4300-be53-cc40c7700b3e",
   "metadata": {
    "id": "8ce51ed3-f5c7-4300-be53-cc40c7700b3e"
   },
   "source": [
    "## **2.Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c00bf3b-6979-4282-b559-013ceef1e3c8",
   "metadata": {
    "id": "4c00bf3b-6979-4282-b559-013ceef1e3c8",
    "outputId": "c93b4361-586c-44ee-9904-dbd94bb732d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.1300 - loss: 2.6267 \n",
      "Epoch 2/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3000 - loss: 2.1173\n",
      "Epoch 3/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5800 - loss: 1.4626\n",
      "Epoch 4/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9400 - loss: 0.9345\n",
      "Epoch 5/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9700 - loss: 0.5763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x145a19150>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "\n",
    "# Generate dummy image data\n",
    "X_train = np.random.rand(100, 32, 32, 3)  # Added channel dimension (RGB)\n",
    "y_train = np.random.randint(0, 10, size=(100,))\n",
    "\n",
    "# Define CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15215ade-6c2c-4159-b400-42a8537267bf",
   "metadata": {
    "id": "15215ade-6c2c-4159-b400-42a8537267bf"
   },
   "source": [
    "## **3.Undefined Variable Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7fc93d2-4027-4a84-ae6e-c60622d7fb38",
   "metadata": {
    "id": "b7fc93d2-4027-4a84-ae6e-c60622d7fb38",
    "outputId": "00703b74-8081-48d1-cafa-465c6e41931d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21628/3183389490.py:9: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'INIT_LR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m model = Model(inputs=baseModel.input, outputs=headModel)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Define missing variables\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m opt = tf.keras.optimizers.Adam(learning_rate=INIT_LR)\n\u001b[32m     19\u001b[39m lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n\u001b[32m     20\u001b[39m     initial_learning_rate=INIT_LR,\n\u001b[32m     21\u001b[39m     decay_steps=\u001b[32m1000\u001b[39m,  \u001b[38;5;66;03m# Adjust this based on dataset size\u001b[39;00m\n\u001b[32m     22\u001b[39m     decay_rate=\u001b[32m0.96\u001b[39m,  \u001b[38;5;66;03m# Reduce LR by 4% every 1000 steps\u001b[39;00m\n\u001b[32m     23\u001b[39m     staircase=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     24\u001b[39m )\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Compile model\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'INIT_LR' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D, Flatten, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load pre-trained MobileNetV2 model\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# Add custom layers\n",
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "# Define missing variables\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=INIT_LR)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=INIT_LR,\n",
    "    decay_steps=1000,  # Adjust this based on dataset size\n",
    "    decay_rate=0.96,  # Reduce LR by 4% every 1000 steps\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "opt = Adam(learning_rate=INIT_LR)  # Error: Undefined variables\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "print(\"Model compiled successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b72ae-a80b-4284-bf19-a40b3a3c9f44",
   "metadata": {
    "id": "e80b72ae-a80b-4284-bf19-a40b3a3c9f44"
   },
   "source": [
    "## **3. Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345249e5-3704-4743-a95e-a47596a5a29f",
   "metadata": {
    "id": "345249e5-3704-4743-a95e-a47596a5a29f",
    "outputId": "673dd248-8450-47e2-ff18-9ead58ea7742"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21628/1375197628.py:9: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D, Flatten, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load pre-trained MobileNetV2 model\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# Add custom layers\n",
    "headModel = baseModel.output\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "# Define missing variables\n",
    "INIT_LR = 0.0001\n",
    "EPOCHS = 20\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=INIT_LR)\n",
    "# Alternative: Use Learning Rate Scheduler if decay is needed\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=INIT_LR,\n",
    "    decay_steps=1000,  # Adjust this based on dataset size\n",
    "    decay_rate=0.96,  # Reduce LR by 4% every 1000 steps\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "opt = Adam(learning_rate=INIT_LR)  # Error: Undefined variables\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "print(\"Model compiled successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c938fb3-b5a9-497a-8fb4-b8f8d7128a61",
   "metadata": {
    "id": "2c938fb3-b5a9-497a-8fb4-b8f8d7128a61"
   },
   "source": [
    " **4.FileNotFoundError                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49b425f7-cdf1-4951-9b20-27396d547a2a",
   "metadata": {
    "id": "49b425f7-cdf1-4951-9b20-27396d547a2a",
    "outputId": "7ba97622-04f6-4a77-890c-ffbbf900fcc6"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'flow.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ❌ ERROR: Wrong file name or missing file\u001b[39;00m\n\u001b[32m      4\u001b[39m image_path = \u001b[33m\"\u001b[39m\u001b[33mflow.jpg\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m img = Image.open(image_path)  \u001b[38;5;66;03m# This will raise a FileNotFoundError\u001b[39;00m\n\u001b[32m      7\u001b[39m img.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/anaconda3/envs/myenv/lib/python3.11/site-packages/PIL/Image.py:3493\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[32m   3492\u001b[39m     filename = os.fspath(fp)\n\u001b[32m-> \u001b[39m\u001b[32m3493\u001b[39m     fp = builtins.open(filename, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   3494\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3495\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'flow.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# ❌ ERROR: Wrong file name or missing file\n",
    "image_path = \"flow.jpg\"\n",
    "img = Image.open(image_path)  # This will raise a FileNotFoundError\n",
    "\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c7b872-6252-47e3-ad88-edc650b44c26",
   "metadata": {
    "id": "a5c7b872-6252-47e3-ad88-edc650b44c26",
    "outputId": "06c2af11-199d-47d8-cbcc-b5b955d7148b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'flower.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m image_path = \u001b[33m\"\u001b[39m\u001b[33mflower.jpg\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Provide the correct path\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ✅ Open the image properly using PIL\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m img = Image.open(image_path)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# ✅ Correctly resize the image (Use tuple)\u001b[39;00m\n\u001b[32m     14\u001b[39m img = img.resize((\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/anaconda3/envs/myenv/lib/python3.11/site-packages/PIL/Image.py:3493\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[32m   3492\u001b[39m     filename = os.fspath(fp)\n\u001b[32m-> \u001b[39m\u001b[32m3493\u001b[39m     fp = builtins.open(filename, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   3494\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3495\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'flower.jpg'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# ✅ Corrected file path (Make sure the file exists)\n",
    "image_path = \"flower.jpg\"  # Provide the correct path\n",
    "\n",
    "# ✅ Open the image properly using PIL\n",
    "img = Image.open(image_path)\n",
    "\n",
    "# ✅ Correctly resize the image (Use tuple)\n",
    "img = img.resize((224, 224))\n",
    "\n",
    "# ✅ Convert image to array before expanding dimensions\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# ✅ Expand dimensions correctly for model input\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# ✅ Preprocess image for MobileNetV2\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "print(\"Preprocessed image shape:\", img_array.shape)  # Expected Output: (1, 224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e9680-0566-433a-9c97-365eaa1fb575",
   "metadata": {
    "id": "9d0e9680-0566-433a-9c97-365eaa1fb575"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
